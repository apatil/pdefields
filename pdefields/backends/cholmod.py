"""
A linear algebra backend that uses sparse, cholesky-based operations.
"""
__all__ = ['into_matrix_type', 'precision_to_products', 'pattern_to_products', 'rmvn', 'mvn_logp', 'axpy', 'dm_solve_m', 'm_mul_m', 'm_xtyx']

import numpy as np
import scipy
from scipy import sparse
import scikits.sparse.cholmod as cholmod

precision_product_keys = ['L','P','F']

def into_matrix_type(m):
    "Takes a matrix m and returns a representation of it as a SciPy compressed sparse column matrix. This is the matrix format used by the CHOLMOD wrapper in scikits.sparse."
    return sparse.csc.csc_matrix(m)
    
def axpy(a,x,y):
    "a,x,y -> ax+y"
    return a*x + y

def dm_solve_m(x,y):
    "A^{-1} B, where A is diagonal and B is CSC."
    x_i = x.copy()
    x_i.data = 1./x_i.data
    return x_i * y

def m_xtyx(x,y):
    "x,y -> x^T y x ."
    return x.T*y*x

def m_mul_m(x,y):
    "x,y -> xy"
    return x*y

def pattern_to_products(pattern):
    """Takes a sparse matrix with the correct sparsity pattern, but not necessarily meaningful values, and returns the symbolic Cholesky factorization of it, computed by CHOLMOD via scikits.sparse. The symbolic factorization is stored in a Factor object. Its method P can be called to obtain the permutation vector. I don't know if there's any way to get the actual sparsity pattern out, but it can surely be done.
    
    The return value is stored in a singleton dictionary with one key, 'symbolic'. It is stored in a dictionary to make it possible to have a uniform return type across all backends."""
    return {'symbolic': cholmod.analyze(pattern)}

def precision_to_products(Q, symbolic):
    """Takes a sparse precision matrix Q and a symbolic Cholesky factorization 'symbolic' and returns several derivative products in a dictionary:
    - Q: The input precision matrix, unaltered.
    - F: The Factor object generated by scikits.sparse. This object supports quick and easy triangular solves.
    - det: The determinant of Q.
    - P: A permutation vector. L is the Cholesky factor of Q[P,:][:,P].
    - Pbak: The backward permutation vector. x[P][Pbax] = x, and (LL^T)[Pbak,:][:,Pbak] = :
    - """
    F = symbolic.cholesky(Q)
    D = F.D()
    det = np.sum(np.log(D))
    P = symbolic.P()
    Pbak = np.argsort(P)
    return {'det':det, 'P': P, 'F': F, 'Pbak': Pbak, 'Q': Q}

def rmvn(M,Q,det,F,P,Pbak):
    """
    Takes the following:
    - M: A mean vector
    - Q: A sparse precision matrix
    - det: The determinant of Q
    - F: A scikits.sparse Factor object representing the Cholesky factorization of Q
    - P: A permutation vector
    - Pbak: The permutation vector that inverts P.
    Returns a draw from the multivariate normal distribution ith mean M and precision P
    """
    return M+F.solve_Lt(np.random.normal(size=len(M)))[Pbak]

def mvn_logp(x,M,Q,det,F,P,Pbak):
    """
    Takes the following:
    - x: A candidate value as a vector.
    - M: A mean vector
    - Q: A sparse precision matrix
    - det: The determinant of Q
    - F: A scikits.sparse Factor object representing the Cholesky factorization of Q
    - P: A permutation vector
    - Pbak: The permutation vector that inverts P.
    Returns the log-probability of x given M and Q.
     """
    d = (x-M)[P]
    return -.5*np.dot(d,Q*d) + .5*det - .5*len(M)*np.log(2.*np.pi)

if __name__ == '__main__':
    OK = False
    while OK==False:
        try:
            B = np.random.normal(size=(100,100))
            ind = np.arange(B.shape[0])
            for i in xrange(B.shape[0]):
                np.random.shuffle(ind)
                B[i,ind[:B.shape[0]-5]]=0
    
            A = sparse.csc_matrix(np.dot(B,B.T))
            # A = sparse.csc_matrix(np.eye(100)*np.random.random(size=100))
            pattern_products = pattern_to_products(A)
            precision_products = precision_to_products(A, **pattern_products)
            OK = True
        except:
            pass
    m = np.random.normal(size=A.shape[0])
    x = np.random.normal(size=A.shape[0])    
    l1  = mvn_logp(x,m,**precision_products)
    import pymc as pm
    l2 = pm.mv_normal_like(x,m,A.todense())
    print l1,l2
    # # z = [rand(m,precision_products,1) for i in xrange(1000)]
    # # C_empirical = np.cov(np.array(z).T)