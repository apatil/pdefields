# -*- coding: UTF-8 -*-
"""
A linear algebra backend that uses sparse, cholesky-based operations.
"""

# The __all__ list defines the interface every backend must expose.
__all__ = ['into_matrix_type', 'precision_to_products', 'pattern_to_products', 'rmvn', 'mvn_logp', 'axpy', 'dm_solve_m', 'm_mul_m', 'm_xtyx', 'conditional_mean_and_precision_products', 'NonPositiveDefiniteError', 'precision_solve_v']

import numpy as np
import scipy
from scipy import sparse
import scikits.sparse.cholmod as cholmod

precision_product_keys = ['L','P','F']

NonPositiveDefiniteError = cholmod.CholmodError

def into_matrix_type(m):
    "Takes a matrix m and returns a representation of it as a SciPy compressed sparse column matrix. This is the matrix format used by the CHOLMOD wrapper in scikits.sparse."
    return sparse.csc.csc_matrix(m)
    
def axpy(a,x,y):
    "a,x,y -> ax+y"
    return np.asscalar(a)*x + y

def dm_solve_m(x,y):
    "A^{-1} B, where A is diagonal and B is CSC."
    x_i = x.copy()
    x_i.data = 1./x_i.data
    return x_i * y

def m_xtyx(x,y):
    "x,y -> x^T y x ."
    # Do it this way to stay in CSC format.
    return x.__rmul__(x.T*y)

def m_mul_m(x,y):
    "x,y -> xy"
    return x*y
    
def pattern_to_products(pattern):
    """Takes a sparse matrix with the correct sparsity pattern, but not necessarily meaningful values, and returns the symbolic Cholesky factorization of it, computed by CHOLMOD via scikits.sparse. The symbolic factorization is stored in a Factor object. Its method P can be called to obtain the permutation vector. I don't know if there's any way to get the actual sparsity pattern out, but it can surely be done.
    
    The return value is stored in a singleton dictionary with one key, 'symbolic'. It is stored in a dictionary to make it possible to have a uniform return type across all backends."""
    return {'symbolic': cholmod.analyze(pattern)}

def increment_diagonal(m,inc):
    "Adds inc to the diagonal of m in-place."
    # FIXME: This is ridiculous. Do it in Fortran.
    return m + sparse.dia_matrix((inc,0), m.shape).tocsc()

def precision_to_products(Q, symbolic):
    """
    Takes a sparse precision matrix Q and a symbolic Cholesky factorization 'symbolic' and returns several derivative products in a dictionary:
    - Q: The input precision matrix, unaltered.
    - F: The Factor object generated by scikits.sparse. This object supports quick and easy triangular solves.
    - det: The determinant of Q.
    - P: A permutation vector. Cholmod computes the Cholesky factorization LDL^T = Q[P,:][:,P].
    - Pbak: The backward permutation vector. x[P][Pbax] = x, and (LDL^T)[Pbak,:][:,Pbak] = Q
    - sqrtD: sqrt(D).
    - """
    F = symbolic.cholesky(Q)
    D = F.D()
    sqrtD = np.sqrt(D)
    det = np.sum(np.log(D))
    P = symbolic.P()
    Pbak = np.argsort(P)
    return {'det':det, 'P': P, 'F': F, 'Pbak': Pbak, 'Q': Q, 'sqrtD': sqrtD}

def precision_solve_v(Q,v,diag,symbolic):
    "(Q+diag)^{-1} v, where Q is CSC and has been analyzed by pattern_to_products and v and diag are vectors."
    # Q_new = Q.copy()
    # Q_new.setdiag(Q.diagonal()+diag)
    Q_new = increment_diagonal(Q,diag)
    precprod = precision_to_products(Q_new, symbolic)
    return precprod['F'].solve_A(v), precprod

def rmvn(M,Q,det,F,P,Pbak,sqrtD):
    """
    Takes the following:
    - M: A mean vector
    - Q: A sparse precision matrix
    - det: The determinant of Q
    - F: A scikits.sparse Factor object representing the Cholesky factorization of Q
    - P: A permutation vector
    - Pbak: The permutation vector that inverts P.
    - sqrtD: The square root of the diagonal matrix D from Cholmod's Cholesky factorization.
    Returns a draw from the multivariate normal distribution ith mean M and precision P
    """
    return M + F.solve_Lt(np.random.normal(size=len(M)) / sqrtD)[Pbak]

def mvn_logp(x,M,Q,det,F,P,Pbak,sqrtD):
    """
    Takes the following:
    - x: A candidate value as a vector.
    - M: A mean vector
    - Q: A sparse precision matrix
    - det: The determinant of Q
    - F: A scikits.sparse Factor object representing the Cholesky factorization of Q
    - P: A permutation vector
    - Pbak: The permutation vector that inverts P.
    - sqrtD: The square root of the diagonal matrix D from Cholmod's Cholesky factorization.    
    Returns the log-probability of x given M and Q.
     """
    d = (x-M)
    return -.5*np.dot(d,Q*d) + .5*det - .5*len(M)*np.log(2.*np.pi)
    
def conditional_mean_and_precision_products(y,M,Q_conditional,Q_obs,symbolic,L_obs=None,K_obs=None):
    """    
    Returns the conditional mean and precision of x in the conjugate submodel
    
    x ~ N(M,Q^{-1})
    y ~ N(L_obs x + K_obs, Q_obs^{-1})
    
    Takes:
    - Observed value of y
    - Mean vector M
    - Sparse SPD matrices Q_conditional (the precision of x conditional on y) and Qobs
    - Sparse matrix, dense matrix or LinearOperator L_obs (optional)
    - Offset vector K_obs (optional)
    - Symbolic Cholesky factorization previously returned by conditional_mean_and_precision (optional)
    
    Returns:
    - Conditional mean
    - The output of precision_to_products, applied to the conditional precision.
    """
    # Note that the joint precision is
    # [Q + L_obs' Q_obs L_obs      -L_obs' Q_obs]
    # [-Q_obs L_obs                 Q_obs]
    
    # Numeric factorization and conditional mean.
    if L_obs is None:
        LM = M
        LQ_obs = Q_obs
    else:
        LM = L_obs*M
        LQ_obs = L_obs.T*Q_obs
    
    if K_obs is None:
        delta = y-LM
    else:
        delta = y-LM-K_obs
        
    Qc_precprod = precision_to_products(Q_conditional,symbolic)
    
    Mc = M + Qc_precprod['F'].solve_A(LQ_obs*delta).reshape(M.shape)

    return Mc, Qc_precprod
    
# if __name__ == '__main__':
#     n = 100
#     nobs = 50
#     B = np.random.normal(size=(n,n)).view(np.matrix)
#     Q = B*B.T
#     L = np.random.normal(size=(n,nobs)).view(np.matrix)
#     M = np.random.normal(size=n).reshape((-1,1))
#     
#     B = np.random.normal(size=(nobs,nobs)).view(np.matrix)
#     Qobs = B*B.T
#     
#     Cx = Q.I
#     Cxy = L.T * Cx
#     Cy = L.T* Cx * L + Qobs.I
#     Ccombo = np.bmat([[Cx,Cxy.T],[Cxy,Cy]])
# 
#     Qcombo = Ccombo.I
#     Qx = Q + L*Qobs*L.T
#     Qxy = -L*Qobs
#     # Qcombo_ = np.bmat([[Qx,Qxy],[Qxy.T,Qobs]])
#     
#     # Equivalent.
#     Ccond = Cx-Cxy.T*Cy.I*Cxy
#     # Ccond_try = Qcombo_[:n,:n].I
#     
#     xobs = L.T*M + np.dot(np.linalg.cholesky(Cy), np.random.normal(size=nobs)).reshape((-1,1))
#     Mcond = M+Cxy.T*Cy.I*(xobs-L.T*M)
#     
#     # eta = Qcombo_*np.vstack((M,L.T*M))
#     # etacond = eta[:n]-Qxy*xobs
#     # Mcond_try = Qx.I*etacond
#     # Mcond_try = M+Qx.I*L*Qobs*(xobs-L.T*M)
#     
#     Qx_try, symbolic, numeric, Mcond_try = conditional_mean_and_precision(xobs, M, *map(sparse.csc_matrix, [Q, Qobs, L.T]))
#     
#     print np.abs(Mcond_try.view(np.ndarray).ravel()-Mcond.view(np.ndarray).ravel()).max()
#     